{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eed82cec",
   "metadata": {},
   "source": [
    "# 维度\n",
    "## 创建多维数据\n",
    "维护一个车辆数据信息，每一个数据，代表的是一辆车的百公里加速时间，首先就是要创建一个车辆百公里加速的列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74c3bb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据： [ 5 10 12  6] \n",
      "维度： 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "cars = np.array([5, 10, 12, 6])\n",
    "print(\"数据：\", cars, \"\\n维度：\", cars.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5bbb56",
   "metadata": {},
   "source": [
    "cars.ndim 会返回给你一个维度的属性，现在这组数据是一个一维数据。你可以认为这是某一次测试 4 款车收集到的数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10144ccb",
   "metadata": {},
   "source": [
    "|  测试批   | car1  |car2  |car3  |car4  |\n",
    "|  ----  | ----  | ----  | ----  | ----  |\n",
    "| 1  | 5 |10 | 12 |6 |  \n",
    "|2  | 5.1 |8.2 |11 |6.3 |  \n",
    "|3 |4.4 |9.1 |10 |6.6 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5978362a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据：\n",
      " [[ 5.  10.  12.   6. ]\n",
      " [ 5.1  8.2 11.   6.3]\n",
      " [ 4.4  9.1 10.   6.6]] \n",
      "维度： 2\n"
     ]
    }
   ],
   "source": [
    "cars = np.array([\n",
    "[5, 10, 12, 6],\n",
    "[5.1, 8.2, 11, 6.3],\n",
    "[4.4, 9.1, 10, 6.6]\n",
    "])\n",
    "\n",
    "print(\"数据：\\n\", cars, \"\\n维度：\", cars.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dea63e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总维度： 3\n",
      "场地 1 数据：\n",
      " [[ 5.  10.  12.   6. ]\n",
      " [ 5.1  8.2 11.   6.3]\n",
      " [ 4.4  9.1 10.   6.6]] \n",
      "场地 1 维度： 2\n",
      "场地 2 数据：\n",
      " [[ 6.  11.  13.   7. ]\n",
      " [ 6.1  9.2 12.   7.3]\n",
      " [ 5.4 10.1 11.   7.6]] \n",
      "场地 2 维度： 2\n"
     ]
    }
   ],
   "source": [
    "cars = np.array([\n",
    "[\n",
    "    [5, 10, 12, 6],\n",
    "    [5.1, 8.2, 11, 6.3],\n",
    "    [4.4, 9.1, 10, 6.6]\n",
    "],\n",
    "[\n",
    "    [6, 11, 13, 7],\n",
    "    [6.1, 9.2, 12, 7.3],\n",
    "    [5.4, 10.1, 11, 7.6]\n",
    "],\n",
    "])\n",
    "\n",
    "print(\"总维度：\", cars.ndim)\n",
    "print(\"场地 1 数据：\\n\", cars[0], \"\\n场地 1 维度：\", cars[0].ndim)\n",
    "print(\"场地 2 数据：\\n\", cars[1], \"\\n场地 2 维度：\", cars[1].ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dfcfeb",
   "metadata": {},
   "source": [
    "## 添加数据\n",
    "在原数据的基础上，要新增一条"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e51f0a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.  10.  12.   6.   5.2  4.2]\n"
     ]
    }
   ],
   "source": [
    "cars1 = np.array([5, 10, 12, 6])\n",
    "cars2 = np.array([5.2, 4.2])\n",
    "cars = np.concatenate([cars1, cars2])\n",
    "print(cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc31347",
   "metadata": {},
   "source": [
    "这种一维的数据很简单，也很好理解，就和 Python 中的 List 添加很像。但是如果数据换成了二维呢？我要添加一组测试数据呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "336c2295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1加维度后  [[ 5 10 12  6]]\n",
      "test2加维度后  [[ 5.1  8.2 11.   6.3]]\n",
      "括展后\n",
      " [[ 5.  10.  12.   6. ]\n",
      " [ 5.1  8.2 11.   6.3]]\n"
     ]
    }
   ],
   "source": [
    "test1 = np.array([5, 10, 12, 6])\n",
    "test2 = np.array([5.1, 8.2, 11, 6.3])\n",
    "\n",
    "# 首先需要把它们都变成二维，下面这两种方法都可以加维度\n",
    "test1 = np.expand_dims(test1, 0)\n",
    "test2 = test2[np.newaxis, :]\n",
    "\n",
    "print(\"test1加维度后 \", test1)\n",
    "print(\"test2加维度后 \", test2)\n",
    "\n",
    "# 然后再在第一个维度上叠加\n",
    "all_tests = np.concatenate([test1, test2])\n",
    "print(\"括展后\\n\", all_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825ea2e6",
   "metadata": {},
   "source": [
    "## 合并数据\n",
    "能在第一个维度上叠加，那你能不能在第二个维度上叠加呢？当然可以，只需要巧妙给 np.concatenate 一个参数就好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df87a0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一维度叠加：\n",
      " [[ 5.  10.  12.   6. ]\n",
      " [ 5.1  8.2 11.   6.3]\n",
      " [ 5.  10.  12.   6. ]\n",
      " [ 5.1  8.2 11.   6.3]]\n",
      "第二维度叠加：\n",
      " [[ 5.  10.  12.   6.   5.  10.  12.   6. ]\n",
      " [ 5.1  8.2 11.   6.3  5.1  8.2 11.   6.3]]\n"
     ]
    }
   ],
   "source": [
    "print(\"第一维度叠加：\\n\", np.concatenate([all_tests, all_tests], axis=0))\n",
    "print(\"第二维度叠加：\\n\", np.concatenate([all_tests, all_tests], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ec1cba",
   "metadata": {},
   "source": [
    "注意，有些数据维度是对不齐的，这样没办法合并。比如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2860d7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  7  8]\n",
      " [ 4  5  6  9 10]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([\n",
    "[1,2,3],\n",
    "[4,5,6]\n",
    "])\n",
    "b = np.array([\n",
    "[7,8],\n",
    "[9,10]\n",
    "])\n",
    "\n",
    "print(np.concatenate([a,b], axis=1))  # 这个没问题\n",
    "# print(np.concatenate([a,b], axis=0))  # 这个会报错"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7dcc38",
   "metadata": {},
   "source": [
    "除了 np.concatenate()，还有两个比较好用的在二维数据上可以方便调用的功能，分别是 np.vstack(), np.hstack()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b88f4154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "竖直合并\n",
      " [[1 2]\n",
      " [3 4]\n",
      " [5 6]\n",
      " [7 8]]\n",
      "水平合并\n",
      " [[1 2 5 6]\n",
      " [3 4 7 8]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([\n",
    "[1,2],\n",
    "[3,4]\n",
    "])\n",
    "b = np.array([\n",
    "[5,6],\n",
    "[7,8]\n",
    "])\n",
    "print(\"竖直合并\\n\", np.vstack([a, b]))\n",
    "print(\"水平合并\\n\", np.hstack([a, b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed872e1",
   "metadata": {},
   "source": [
    "## 观察形态\n",
    "np.ndim 来查看数据的形态，其实我们有时候还想更加了解数据的细节问题，比如这个数据的大小，规格。方便我们管理这些数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7144c708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总共多少测试数据： 12\n"
     ]
    }
   ],
   "source": [
    "cars = np.array([\n",
    "[5, 10, 12, 6],\n",
    "[5.1, 8.2, 11, 6.3],\n",
    "[4.4, 9.1, 10, 6.6]\n",
    "])\n",
    "\n",
    "count = 0\n",
    "for i in range(len(cars)):\n",
    "    for j in range(len(cars[i])):\n",
    "        count += 1\n",
    "print(\"总共多少测试数据：\", count)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584d3b98",
   "metadata": {},
   "source": [
    "其实 Numpy 还有更好用的方式获取总个数。看看使用 cars.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ad92753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总共多少测试数据： 12\n"
     ]
    }
   ],
   "source": [
    "print(\"总共多少测试数据：\", cars.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b773ea2",
   "metadata": {},
   "source": [
    "更进一步，我不光想知道总数据，我还想知道当前有多少次测试（第一个维度，行），和在多少辆车上测试了（第二个维度，列）。怎么办？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6c002e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一个维度： 3\n",
      "第二个维度： 4\n",
      "所有维度： (3, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"第一个维度：\", cars.shape[0])\n",
    "print(\"第二个维度：\", cars.shape[1])\n",
    "print(\"所有维度：\", cars.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593e91f0",
   "metadata": {},
   "source": [
    "# 数据选取\n",
    "## 单个选取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce043b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a[0]: 1\n",
      "a[1]: 2\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "print(\"a[0]:\", a[0])\n",
    "print(\"a[1]:\", a[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a3ce75",
   "metadata": {},
   "source": [
    "当然还有种方法，可以一次性选择多个，但实际上选择的逻辑还是一个个拎出来的逻辑。就像一个个从抽屉里拿出来的意思。后面我们还会介绍一批拿出来的概念（切片划分）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8290b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a[[0,1]]:\n",
      " [1 2]\n",
      "a[[1,1,0]]:\n",
      " [2 2 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"a[[0,1]]:\\n\", a[[0,1]])\n",
    "print(\"a[[1,1,0]]:\\n\", a[[1,1,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab75794a",
   "metadata": {},
   "source": [
    "二维或者多维数据也可以用上面的方法来选择数据，一个个拎出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1cfd478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b[1]:\n",
      " [5 6 7 8]\n",
      "b[1,0]:\n",
      " 5\n",
      "b[[1,0],[2,3]]:\n",
      " [7 4]\n"
     ]
    }
   ],
   "source": [
    "b = np.array([\n",
    "[1,2,3,4],\n",
    "[5,6,7,8],\n",
    "[9,10,11,12]\n",
    "])\n",
    "\n",
    "# 选第 2 行所有数\n",
    "print(\"b[1]:\\n\", b[1])   \n",
    "\n",
    "# 选第 2 行，第 1 列的数\n",
    "print(\"b[1,0]:\\n\", b[1,0])   \n",
    "\n",
    "# 这个看着有点纠结，如果对应到数据，\n",
    "# 第一个拿的是数据位是 [1,2]\n",
    "# 第二个拿的是 [0,3]\n",
    "print(\"b[[1,0],[2,3]]:\\n\", \n",
    "b[[1,0],\n",
    "[2,3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2144c639",
   "metadata": {},
   "source": [
    "## 切片划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d02c730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a[0:2]：\n",
      " [1 2]\n",
      "a[1:]：\n",
      " [2 3]\n",
      "a[-2:]：\n",
      " [2 3]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "print(\"a[0:2]：\\n\", a[0:2])\n",
    "print(\"a[1:]：\\n\", a[1:])\n",
    "print(\"a[-2:]：\\n\", a[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc12a05",
   "metadata": {},
   "source": [
    "使用 : 就能让你跨着取数字，而且一次取一批。注意，在 Numpy 中：一次取一批和一个个拎起来，拎了一批，是不同的概念哦 一次取一批来的更快， 因为它不用去一个个查看，一个个数了。   \n",
    "\n",
    "在多维上，也可以进行切片划分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e1cb7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b[:2]:\n",
      " [[1 2 3 4]\n",
      " [5 6 7 8]]\n",
      "b[:2, :3]:\n",
      " [[1 2 3]\n",
      " [5 6 7]]\n",
      "b[1:3, -2:]:\n",
      " [[ 7  8]\n",
      " [11 12]]\n"
     ]
    }
   ],
   "source": [
    "b = np.array([\n",
    "[1,2,3,4],\n",
    "[5,6,7,8],\n",
    "[9,10,11,12]\n",
    "])\n",
    "\n",
    "print(\"b[:2]:\\n\", b[:2])\n",
    "print(\"b[:2, :3]:\\n\", b[:2, :3])\n",
    "print(\"b[1:3, -2:]:\\n\", b[1:3, -2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d63b4f",
   "metadata": {},
   "source": [
    "## 条件筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71841e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8  9 10 11 12]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([\n",
    "[1,2,3,4],\n",
    "[5,6,7,8],\n",
    "[9,10,11,12]\n",
    "])\n",
    "\n",
    "print(a[a>7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58b75d5",
   "metadata": {},
   "source": [
    "我们再拆开来看，a[a>7] 这里面究竟发生了什么。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f00c9a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False False]\n",
      " [False False False  True]\n",
      " [ True  True  True  True]]\n",
      "[ 8  9 10 11 12]\n"
     ]
    }
   ],
   "source": [
    "condition = a > 7\n",
    "print(condition)\n",
    "\n",
    "print(a[condition])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f9a725",
   "metadata": {},
   "source": [
    "condition 是一种 True/False, 那么只要我们得到一个 True/False 数据，我都能做筛选。这才是它筛选的底层逻辑了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94700918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8  9 11 12]\n"
     ]
    }
   ],
   "source": [
    "condition = (a > 7) & (a != 10)\n",
    "print(a[condition])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a81413",
   "metadata": {},
   "source": [
    "除了这种直接用[]的形式，在 Numpy 中，还有一个专用的函数来做数据筛选。这种筛选更强大，它还能做筛选结果的替换工作。 它可已将满足条件的位置变成你设定的数字。下面满足条件的，都改成 -1，不满足的，都还是 a 里面的数字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "faf73499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4]\n",
      " [ 5  6  7 -1]\n",
      " [-1 -1 -1 -1]]\n"
     ]
    }
   ],
   "source": [
    "condition = a > 7\n",
    "print(np.where(condition, -1, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2167ca3",
   "metadata": {},
   "source": [
    "不仅是满足条件的 condition，不满足条件的，也能变成你期望的数字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97787ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  2  2  2]\n",
      " [ 2  2  2 -1]\n",
      " [-1 -1 -1 -1]]\n"
     ]
    }
   ],
   "source": [
    "condition = a > 7\n",
    "print(np.where(condition, -1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fca9b7",
   "metadata": {},
   "source": [
    "不光是数字哦，我还能让它和另外一个数据做条件上的整合哦，比如下面这样。如果满足 condition 要求，那么就会在对应的 True 位置放上 a 里的值，如果不满足 condition 要求，也就是在 condition 为 False 的地方放上 b 里对应位置的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e4342f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2 -3 -4 -5]\n",
      " [-6 -7 -8  8]\n",
      " [ 9 10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "condition = a > 7\n",
    "b = -a - 1\n",
    "print(np.where(condition, a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2688a2",
   "metadata": {},
   "source": [
    "# 基础运算\n",
    "## 加减乘除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29c62e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[153, 169, 186, 173]\n"
     ]
    }
   ],
   "source": [
    "l = [150, 166, 183, 170]\n",
    "for i in range(len(l)):\n",
    "    l[i] += 3\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b16a62c",
   "metadata": {},
   "source": [
    "用列表你需要使用到一个循环，或者是一个map函数来帮你实现这个功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "098a2959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[153, 169, 186, 173]\n"
     ]
    }
   ],
   "source": [
    "print(list(map(lambda x: x+3, [150, 166, 183, 170])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a41f120",
   "metadata": {},
   "source": [
    "如果我们用 Numpy 的方式来实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6561569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[153 169 186 173]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([150, 166, 183, 170])\n",
    "print(a + 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da4085d",
   "metadata": {},
   "source": [
    "Numpy 是可以批量进行计算的，只需要简单的 +-*/，就能进行全元素的运算，也就是向量化运算。同理，我们也可以进行其他符号的批量运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8773f81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a + 3: [153 169 186 173]\n",
      "a - 3: [147 163 180 167]\n",
      "a * 3: [450 498 549 510]\n",
      "a / 3: [50.         55.33333333 61.         56.66666667]\n"
     ]
    }
   ],
   "source": [
    "print(\"a + 3:\", a + 3)\n",
    "print(\"a - 3:\", a - 3)\n",
    "print(\"a * 3:\", a * 3)\n",
    "print(\"a / 3:\", a / 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c09c3df",
   "metadata": {},
   "source": [
    "机器学习中最常用的矩阵点积运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6387bd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19 22]\n",
      " [43 50]]\n",
      "[[19 22]\n",
      " [43 50]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([\n",
    "[1, 2],\n",
    "[3, 4]\n",
    "])\n",
    "b = np.array([\n",
    "[5, 6],\n",
    "[7, 8]\n",
    "])\n",
    "\n",
    "print(a.dot(b))\n",
    "print(np.dot(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14321c64",
   "metadata": {},
   "source": [
    "## 数据统计分析\n",
    "两种方法可以获取到最大最小，只是不同的写法罢了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08473e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最大： 183\n",
      "最小： 150\n"
     ]
    }
   ],
   "source": [
    "a = np.array([150, 166, 183, 170])\n",
    "print(\"最大：\", np.max(a))\n",
    "print(\"最小：\", a.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d6f6283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669\n"
     ]
    }
   ],
   "source": [
    "print(a.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fdc5a717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "累乘： 774639000\n",
      "总数： 4\n",
      "非零总数： 3\n"
     ]
    }
   ],
   "source": [
    "a = np.array([150, 166, 183, 170])\n",
    "print(\"累乘：\", a.prod())\n",
    "print(\"总数：\", a.size)   \n",
    "                 \n",
    "a = np.array([0, 1, 2, 3])\n",
    "print(\"非零总数：\", np.count_nonzero(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5a9be03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均工资： 4.82\n",
      "工资中位数： 1.2\n"
     ]
    }
   ],
   "source": [
    "month_salary = [1.2, 20, 0.5, 0.3, 2.1]\n",
    "print(\"平均工资：\", np.mean(month_salary))\n",
    "print(\"工资中位数：\", np.median(month_salary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43dcf43",
   "metadata": {},
   "source": [
    "standard deviation 标准差，用来描述正态分布。 这个在机器学习中，特别是深度神经网络中也非常重要，特别用于权重的生成原则。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d157090a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标准差： 7.61614075500184\n"
     ]
    }
   ],
   "source": [
    "month_salary = [1.2, 20, 0.5, 0.3, 2.1]\n",
    "print(\"标准差：\", np.std(month_salary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5a2810",
   "metadata": {},
   "source": [
    "## 特殊运算符号\n",
    "有的时候，其实你不关心 np.max() 或者 np.min() 的数值是多少，而是关心这个数值的序号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "071dac6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Huawei 最高\n",
      "小米 最矮\n"
     ]
    }
   ],
   "source": [
    "a = np.array([150, 166, 183, 170])\n",
    "name = [\"小米\", \"OPPO\", \"Huawei\", \"诺基亚\"]\n",
    "high_idx = np.argmax(a)\n",
    "low_idx = np.argmin(a)\n",
    "print(\"{} 最高\".format(name[high_idx]))\n",
    "print(\"{} 最矮\".format(name[low_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988759d7",
   "metadata": {},
   "source": [
    "取天花板的值还是地板的值，这个在 AI 算法中也比较常见， 比如我要对其做取整处理，抹除小数部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2c09c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ceil: [151. 167. 184. 171.]\n",
      "floor: [150. 166. 183. 170.]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([150.1, 166.4, 183.7, 170.8])\n",
    "print(\"ceil:\", np.ceil(a))\n",
    "print(\"floor:\", np.floor(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c76b52e",
   "metadata": {},
   "source": [
    "还有更自由的取值截取空间时咋办？我可以用 np.clip() 来做上下界限的值截取。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ea5e747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clip: [160.  166.4 180.  170.8]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([150.1, 166.4, 183.7, 170.8])\n",
    "print(\"clip:\", a.clip(160, 180))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132f6cb7",
   "metadata": {},
   "source": [
    "# 改变数据形态\n",
    "## 改变形态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7544aaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6,) (1, 6)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5,6])\n",
    "a_2d = a[np.newaxis, :]\n",
    "print(a.shape, a_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23bca835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4, 5, 6]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ad04de",
   "metadata": {},
   "source": [
    "比如用 None 或者 np.expand_dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c0fb276f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1) (6, 1)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5,6])\n",
    "a_none = a[:, None]\n",
    "a_expand = np.expand_dims(a, axis=1)\n",
    "print(a_none.shape, a_expand.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27b3dcc",
   "metadata": {},
   "source": [
    "除了添加维度，我们还能减少维度，但是下面介绍的减少维度，只能减少那些维度 shape 上为 1 的维度。因为减掉这个维度，数据结构上是没有变化的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bcd4318b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6,)\n",
      "(6,)\n"
     ]
    }
   ],
   "source": [
    "a_squeeze = np.squeeze(a_expand)\n",
    "a_squeeze_axis = a_expand.squeeze(axis=1)\n",
    "print(a_squeeze.shape)\n",
    "print(a_squeeze_axis.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37bf0d9",
   "metadata": {},
   "source": [
    "在机器学习中，我们还有一个更常见的操作，是要改变 shape。维度的添加减少，只能添加减少一个维度，数据结构是不变的。 但是 np.reshape() 可以改变数据结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56b70c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1 shape: (2, 3)\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "a2 shape: (3, 1, 2)\n",
      "[[[1 2]]\n",
      "\n",
      " [[3 4]]\n",
      "\n",
      " [[5 6]]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5,6])\n",
    "a1 = a.reshape([2, 3])\n",
    "a2 = a.reshape([3,1,2])\n",
    "print(\"a1 shape:\", a1.shape)\n",
    "print(a1)\n",
    "print(\"a2 shape:\", a2.shape)\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4bdfb9",
   "metadata": {},
   "source": [
    "其实还有更多的改变形态的方法，比如让数据变直、展平 的 np.ravel(), np.flatten()   \n",
    "也有一种形态的转化，叫做矩阵转置，np.transpose(), 在机器学习中也用得很多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b891a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4]\n",
      " [2 5]\n",
      " [3 6]]\n",
      "[[1 4]\n",
      " [2 5]\n",
      " [3 6]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5,6]).reshape([2, 3])\n",
    "aT1 = a.T\n",
    "aT2 = np.transpose(a)\n",
    "\n",
    "print(aT1)\n",
    "print(aT2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042cb21f",
   "metadata": {},
   "source": [
    "## 合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df48d0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 11]\n",
      " [ 2 22]\n",
      " [ 3 33]\n",
      " [ 4 44]\n",
      " [ 5 55]\n",
      " [ 6 66]]\n"
     ]
    }
   ],
   "source": [
    "feature_a = np.array([1,2,3,4,5,6])\n",
    "feature_b = np.array([11,22,33,44,55,66])\n",
    "c_stack = np.column_stack([feature_a, feature_b])\n",
    "print(c_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e49a1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  1.1]\n",
      " [1.  2.2]]\n"
     ]
    }
   ],
   "source": [
    "sample_a = np.array([0, 1.1])\n",
    "sample_b = np.array([1, 2.2])\n",
    "c_stack = np.row_stack([sample_a, sample_b])\n",
    "print(c_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78828cd",
   "metadata": {},
   "source": [
    "np.column_stack() 和 np.row_stack() 和后面的 np.vstack()、np.hstack() 相比， 有些特殊之处，我们先看看使用 vstack 和 hstack 的案例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ecc8821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 11]\n",
      " [ 2 22]\n",
      " [ 3 33]\n",
      " [ 4 44]\n",
      " [ 5 55]\n",
      " [ 6 66]]\n",
      "[[0.  1.1]\n",
      " [1.  2.2]]\n"
     ]
    }
   ],
   "source": [
    "feature_a = np.array([1,2,3,4,5,6])[:, None]\n",
    "feature_b = np.array([11,22,33,44,55,66])[:, None]\n",
    "c_stack = np.hstack([feature_a, feature_b])\n",
    "print(c_stack)\n",
    "\n",
    "sample_a = np.array([0, 1.1])[None, :]\n",
    "sample_b = np.array([1, 2.2])[None, :]\n",
    "c_stack = np.vstack([sample_a, sample_b])\n",
    "print(c_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431248c9",
   "metadata": {},
   "source": [
    "用 column_stack 和 row_stack() 的时候，Numpy 自动帮你处理的维度信息，而用 vstack 和 hstack 的时候，你需要先确保维度信息是正确的，然后再合并。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd08ff73",
   "metadata": {},
   "source": [
    "你想要用统一的方法来处理各种不同情况的合并，np.concatenate() 是我最喜欢的方法，管它什么 vstack hstack 甚至是在更高维度上要合并， 我们都可以用 concatenate() 一个功能实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "326f93fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]\n",
      " [7 8]]\n",
      "[[1 2 5 6]\n",
      " [3 4 7 8]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([\n",
    "[1,2],\n",
    "[3,4]\n",
    "])\n",
    "b = np.array([\n",
    "[5,6],\n",
    "[7,8]\n",
    "])\n",
    "\n",
    "print(np.concatenate([a, b], axis=0))\n",
    "print(np.concatenate([a, b], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82297d58",
   "metadata": {},
   "source": [
    "## 拆解\n",
    "能横着，竖着合并，那也能横着竖着拆解。np.vsplit() 和 np.hsplit() 就是干这事的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef5f65ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 1, 11,  2, 22],\n",
      "       [ 3, 33,  4, 44]]), array([[ 5, 55,  6, 66],\n",
      "       [ 7, 77,  8, 88]])]\n",
      "[array([[ 1, 11,  2, 22],\n",
      "       [ 3, 33,  4, 44]]), array([[ 5, 55,  6, 66]]), array([[ 7, 77,  8, 88]])]\n"
     ]
    }
   ],
   "source": [
    "a = np.array(\n",
    "[[ 1, 11, 2, 22],\n",
    " [ 3, 33, 4, 44],\n",
    " [ 5, 55, 6, 66],\n",
    " [ 7, 77, 8, 88]]\n",
    ")\n",
    "print(np.vsplit(a, indices_or_sections=2))  # 分成两段\n",
    "print(np.vsplit(a, indices_or_sections=[2,3]))  # 分片成 [:2]，[2:3], [3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dfa489",
   "metadata": {},
   "source": [
    "那么有没有既能横切也能纵切的函数呢？ 当然有呀，和 stack 一样，如果直接用 np.split() 你就能选择要切分的维度来自定义切分了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f9acbd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 1, 11,  2, 22],\n",
      "       [ 3, 33,  4, 44]]), array([[ 5, 55,  6, 66],\n",
      "       [ 7, 77,  8, 88]])]\n",
      "[array([[ 1, 11],\n",
      "       [ 3, 33],\n",
      "       [ 5, 55],\n",
      "       [ 7, 77]]), array([[2],\n",
      "       [4],\n",
      "       [6],\n",
      "       [8]]), array([[22],\n",
      "       [44],\n",
      "       [66],\n",
      "       [88]])]\n"
     ]
    }
   ],
   "source": [
    "a = np.array(\n",
    "[[ 1, 11, 2, 22],\n",
    " [ 3, 33, 4, 44],\n",
    " [ 5, 55, 6, 66],\n",
    " [ 7, 77, 8, 88]]\n",
    ")\n",
    "print(np.split(a, indices_or_sections=2, axis=0))  # 分成两段\n",
    "print(np.split(a, indices_or_sections=[2,3], axis=1))  # 在第二维度，分片成 [:2]，[2:3]，[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0246b92f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
